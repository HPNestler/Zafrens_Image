{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\envs\\images\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\peter\\anaconda3\\envs\\images\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neptunecontrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24252/3109346906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mObjectDetectionDataSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaster_RCNN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFasterRCNN_lightning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaster_RCNN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_fasterRCNN_resnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python_Projects\\Zafrens_Image\\pytorch_faster_rcnn_tutorial\\datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mComposeDouble\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComposeSingle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmap_class_to_int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_faster_rcnn_tutorial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python_Projects\\Zafrens_Image\\pytorch_faster_rcnn_tutorial\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mneptunecontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlog_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeneralizedRCNNTransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbox_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neptunecontrib'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_faster_rcnn_tutorial.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import FasterRCNN_lightning\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import get_fasterRCNN_resnet\n",
    "from pytorch_faster_rcnn_tutorial.transformations import Clip, ComposeDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import AlbumentationWrapper\n",
    "from pytorch_faster_rcnn_tutorial.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import normalize_01\n",
    "from pytorch_faster_rcnn_tutorial.utils import get_filenames_of_path, collate_double\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_mapping_neptune\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_model_neptune\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_packages_neptune\n",
    "\n",
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"hpnestler/zafrens-image\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjYTIwMTFhZi03ZWNhLTQwNWUtOTYwYy02MWZlMWNkZWI5N2MifQ==\",\n",
    ")  # your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "params = {'BATCH_SIZE': 2,\n",
    "          'OWNER': 'hpnestler',  # set your name here, e.g. johndoe22\n",
    "          'SAVE_DIR': None,  # checkpoints will be saved to cwd\n",
    "          'LOG_MODEL': False,  # whether to log the model to neptune after training\n",
    "          'GPU': None,  # set to None for cpu training\n",
    "          'LR': 0.001,\n",
    "          'PRECISION': 32,\n",
    "          'CLASSES': 2,\n",
    "          'SEED': 42,\n",
    "          'PROJECT': 'zafrens-image',\n",
    "          'EXPERIMENT': 'heads',\n",
    "          'MAXEPOCHS': 10,\n",
    "          'BACKBONE': 'resnet34',\n",
    "          'FPN': False,\n",
    "          'ANCHOR_SIZE': ((32, 64, 128, 256, 512),),\n",
    "          'ASPECT_RATIOS': ((0.5, 1.0, 2.0),),\n",
    "          'MIN_SIZE': 1024,\n",
    "          'MAX_SIZE': 1024,\n",
    "          'IMG_MEAN': [0.485, 0.456, 0.406],\n",
    "          'IMG_STD': [0.229, 0.224, 0.225],\n",
    "          'IOU_THRESHOLD': 0.5\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEPTUNE'] = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjYTIwMTFhZi03ZWNhLTQwNWUtOTYwYy02MWZlMWNkZWI5N2MifQ=='\n",
    "\n",
    "#env_var = os.environ\n",
    "#print(env_var)\n",
    "# api key\n",
    "api_key = os.environ['NEPTUNE']  # if this throws an error, you didn't set your env var\n",
    "\n",
    "#api_key = \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjYTIwMTFhZi03ZWNhLTQwNWUtOTYwYy02MWZlMWNkZWI5N2MifQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory\n",
    "if not params['SAVE_DIR']:\n",
    "    save_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = pathlib.Path('pytorch_faster_rcnn_tutorial/data/heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'input')\n",
    "targets = get_filenames_of_path(root / 'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "mapping = {\n",
    "    'head': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble([\n",
    "    Clip(),\n",
    "    AlbumentationWrapper(albumentation=A.HorizontalFlip(p=0.5)),\n",
    "    AlbumentationWrapper(albumentation=A.RandomScale(p=0.5, scale_limit=0.5)),\n",
    "    # AlbuWrapper(albu=A.VerticalFlip(p=0.5)),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transformations\n",
    "transforms_test = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random seed\n",
    "seed_everything(params['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training validation test split\n",
    "inputs_train, inputs_valid, inputs_test = inputs[:12], inputs[12:16], inputs[16:]\n",
    "targets_train, targets_valid, targets_test = targets[:12], targets[12:16], targets[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset training\n",
    "dataset_train = ObjectDetectionDataSet(inputs=inputs_train,\n",
    "                                       targets=targets_train,\n",
    "                                       transform=transforms_training,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset validation\n",
    "dataset_valid = ObjectDetectionDataSet(inputs=inputs_valid,\n",
    "                                       targets=targets_valid,\n",
    "                                       transform=transforms_validation,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset test\n",
    "dataset_test = ObjectDetectionDataSet(inputs=inputs_test,\n",
    "                                      targets=targets_test,\n",
    "                                      transform=transforms_test,\n",
    "                                      use_cache=True,\n",
    "                                      convert_to_format=None,\n",
    "                                      mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader training\n",
    "dataloader_train = DataLoader(dataset=dataset_train,\n",
    "                              batch_size=params['BATCH_SIZE'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader validation\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader test\n",
    "dataloader_test = DataLoader(dataset=dataset_test,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune logger\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=api_key,\n",
    "    project='hpnestler/zafrens-image', # use your neptune name here\n",
    "    name = \"tester\"\n",
    "    #experiment_name=params['EXPERIMENT'],\n",
    "    #params=params\n",
    ")\n",
    "\n",
    "assert neptune_logger.name  # http GET request to check if the project exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_fasterRCNN_resnet(num_classes=params['CLASSES'],\n",
    "                              backbone_name=params['BACKBONE'],\n",
    "                              anchor_size=params['ANCHOR_SIZE'],\n",
    "                              aspect_ratios=params['ASPECT_RATIOS'],\n",
    "                              fpn=params['FPN'],\n",
    "                              min_size=params['MIN_SIZE'],\n",
    "                              max_size=params['MAX_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning init\n",
    "task = FasterRCNN_lightning(model=model, lr=params['LR'], iou_threshold=params['IOU_THRESHOLD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "checkpoint_callback = ModelCheckpoint(monitor='Validation_mAP', mode='max')\n",
    "learningrate_callback = LearningRateMonitor(logging_interval='step', log_momentum=False)\n",
    "early_stopping_callback = EarlyStopping(monitor='Validation_mAP', patience=50, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "# trainer init\n",
    "trainer = Trainer(gpus=params['GPU'],\n",
    "                  precision=params['PRECISION'],  # try 16 with enable_pl_optimizer=False\n",
    "                  callbacks=[checkpoint_callback, learningrate_callback, early_stopping_callback],\n",
    "                  default_root_dir=params['SAVE_DIR'],  # where checkpoints are saved to\n",
    "                  logger=neptune_logger,\n",
    "                  log_every_n_steps=1,\n",
    "                  num_sanity_val_steps=0,\n",
    "                  max_epochs = params['MAXEPOCHS']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/hpnestler/zafrens-image/e/ZAF-10\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | FasterRCNN | 50.4 M\n",
      "-------------------------------------\n",
      "50.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.736   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a80f4baaa84a3bb8090c5616f68dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training\n",
    "#trainer.max_epochs = params['MAXEPOCHS']\n",
    "trainer.fit(task,\n",
    "            train_dataloader=dataloader_train,\n",
    "            val_dataloaders=dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /mnt/raid1/Python_projects/Zafrens_Image/.neptune/tester/ZAF-10/checkpoints/epoch=9-step=59.ckpt\n",
      "Loaded model weights from checkpoint at /mnt/raid1/Python_projects/Zafrens_Image/.neptune/tester/ZAF-10/checkpoints/epoch=9-step=59.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8009514076fc4b49bb08bf77b51669a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test_AP_1': 0.3490897475693392, 'Test_mAP': 0.3490897475693392}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Test_mAP': 0.3490897475693392, 'Test_AP_1': 0.3490897475693392}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start testing\n",
    "trainer.test(ckpt_path='best', test_dataloaders=dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NeptunePossibleLegacyUsageException",
     "evalue": "\n\u001b[95m\n----NeptunePossibleLegacyUsageException----------------------------------------------------------------\n\u001b[0m\nIt seems you are trying to use legacy API, but imported the new one.\n\nSimply update your import statement to:\n    \u001b[96mimport neptune\u001b[0m\n\nYou may want to check the Legacy API docs:\n    - https://docs-legacy.neptune.ai\n\nIf you want to update your code with the new API we prepared a handy migration guide:\n    - https://docs.neptune.ai/migration-guide\n\nYou can read more about neptune.new in the release blog post:\n    - https://neptune.ai/blog/neptune-new\n\nYou may also want to check the following docs pages:\n    - https://docs-legacy.neptune.ai/getting-started/integrate-neptune-into-your-codebase.html\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNeptunePossibleLegacyUsageException\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9015/3704405463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# log packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_packages_neptune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneptune_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/raid1/Python_projects/Zafrens_Image/pytorch_faster_rcnn_tutorial/utils.py\u001b[0m in \u001b[0;36mlog_packages_neptune\u001b[0;34m(neptune_logger)\u001b[0m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mlog_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"packages\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackages_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneptune_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.8/site-packages/neptunecontrib/api/table.py\u001b[0m in \u001b[0;36mlog_table\u001b[0;34m(name, table, experiment)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0m_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mneptune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0m_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tables/{}.html'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.8/site-packages/neptune/new/attribute_container.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEGACY_METHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNeptunePossibleLegacyUsageException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         raise AttributeError(\n\u001b[1;32m    130\u001b[0m             \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{item}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNeptunePossibleLegacyUsageException\u001b[0m: \n\u001b[95m\n----NeptunePossibleLegacyUsageException----------------------------------------------------------------\n\u001b[0m\nIt seems you are trying to use legacy API, but imported the new one.\n\nSimply update your import statement to:\n    \u001b[96mimport neptune\u001b[0m\n\nYou may want to check the Legacy API docs:\n    - https://docs-legacy.neptune.ai\n\nIf you want to update your code with the new API we prepared a handy migration guide:\n    - https://docs.neptune.ai/migration-guide\n\nYou can read more about neptune.new in the release blog post:\n    - https://neptune.ai/blog/neptune-new\n\nYou may also want to check the following docs pages:\n    - https://docs-legacy.neptune.ai/getting-started/integrate-neptune-into-your-codebase.html\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n"
     ]
    }
   ],
   "source": [
    "# log packages\n",
    "log_packages_neptune(neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NeptunePossibleLegacyUsageException",
     "evalue": "\n\u001b[95m\n----NeptunePossibleLegacyUsageException----------------------------------------------------------------\n\u001b[0m\nIt seems you are trying to use legacy API, but imported the new one.\n\nSimply update your import statement to:\n    \u001b[96mimport neptune\u001b[0m\n\nYou may want to check the Legacy API docs:\n    - https://docs-legacy.neptune.ai\n\nIf you want to update your code with the new API we prepared a handy migration guide:\n    - https://docs.neptune.ai/migration-guide\n\nYou can read more about neptune.new in the release blog post:\n    - https://neptune.ai/blog/neptune-new\n\nYou may also want to check the following docs pages:\n    - https://docs-legacy.neptune.ai/getting-started/integrate-neptune-into-your-codebase.html\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNeptunePossibleLegacyUsageException\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9015/2702198034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# log mapping as table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_mapping_neptune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneptune_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/raid1/Python_projects/Zafrens_Image/pytorch_faster_rcnn_tutorial/utils.py\u001b[0m in \u001b[0;36mlog_mapping_neptune\u001b[0;34m(mapping, neptune_logger)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mlog_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneptune_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.8/site-packages/neptunecontrib/api/table.py\u001b[0m in \u001b[0;36mlog_table\u001b[0;34m(name, table, experiment)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0m_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mneptune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0m_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tables/{}.html'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.8/site-packages/neptune/new/attribute_container.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEGACY_METHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNeptunePossibleLegacyUsageException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         raise AttributeError(\n\u001b[1;32m    130\u001b[0m             \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{item}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNeptunePossibleLegacyUsageException\u001b[0m: \n\u001b[95m\n----NeptunePossibleLegacyUsageException----------------------------------------------------------------\n\u001b[0m\nIt seems you are trying to use legacy API, but imported the new one.\n\nSimply update your import statement to:\n    \u001b[96mimport neptune\u001b[0m\n\nYou may want to check the Legacy API docs:\n    - https://docs-legacy.neptune.ai\n\nIf you want to update your code with the new API we prepared a handy migration guide:\n    - https://docs.neptune.ai/migration-guide\n\nYou can read more about neptune.new in the release blog post:\n    - https://neptune.ai/blog/neptune-new\n\nYou may also want to check the following docs pages:\n    - https://docs-legacy.neptune.ai/getting-started/integrate-neptune-into-your-codebase.html\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n"
     ]
    }
   ],
   "source": [
    "# log mapping as table\n",
    "log_mapping_neptune(mapping, neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run ZAF-9 received stop signal. Exiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 3 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "# log model\n",
    "if params['LOG_MODEL']:\n",
    "    checkpoint_path = pathlib.Path(checkpoint_callback.best_model_path)\n",
    "    log_model_neptune(checkpoint_path=checkpoint_path,\n",
    "                      save_directory=pathlib.Path.home(),\n",
    "                      name='best_model.pt',\n",
    "                      neptune_logger=neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
